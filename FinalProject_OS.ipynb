{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cinnamorix/OS_Project_DEMOs/blob/main/FinalProject_OS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install librosa tqdm\n",
        "!pip install joblib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ8DxUJ7eKL6",
        "outputId": "e5e3b249-ec35-443d-c88f-8ce0f6d6dda5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.2)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"carlthome/gtzan-genre-collection\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGbotRwjdwc2",
        "outputId": "02d55006-abaa-41bd-d861-a13a0dc2f0a7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/carlthome/gtzan-genre-collection?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.14G/1.14G [00:19<00:00, 61.5MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/carlthome/gtzan-genre-collection/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸£à¸±à¸™\n",
        "audio_root = f\"{path}/genres\"  # à¸¡à¸µà¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œà¸¢à¹ˆà¸­à¸¢ pop/, rock/, jazz/, ...\n",
        "print(audio_root)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEwAH4IievkY",
        "outputId": "6e9e6047-1a32-4fb2-a25f-a562c819f14f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/carlthome/gtzan-genre-collection/versions/1/genres\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import joblib\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ðŸ”¥ Config\n",
        "AUDIO_ROOT = \"/root/.cache/kagglehub/datasets/carlthome/gtzan-genre-collection/versions/1/genres\"\n",
        "OUTPUT_CSV = \"/content/audio_features_augmented.csv\"\n",
        "FEATURE_CACHE_DIR = \"/content/feature_cache\"\n",
        "os.makedirs(FEATURE_CACHE_DIR, exist_ok=True)\n",
        "\n",
        "#feature\n",
        "\n",
        "def extract_features(y, sr, filename, genre, tag=\"original\"):\n",
        "    try:\n",
        "        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
        "        pitch = librosa.yin(y, fmin=60, fmax=400, sr=sr).mean()\n",
        "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "        mfcc_mean = mfcc.mean(axis=1)\n",
        "\n",
        "        row = {\n",
        "            \"filename\": f\"{filename}_{tag}\",\n",
        "            \"genre\": genre,\n",
        "            \"bpm\": tempo,\n",
        "            \"pitch\": pitch,\n",
        "        }\n",
        "        for i, val in enumerate(mfcc_mean):\n",
        "            row[f\"mfcc_{i}\"] = val\n",
        "\n",
        "        return row\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Feature extraction failed: {filename}: {e}\")\n",
        "        return None\n",
        "\n",
        "# process file + augmentations (with cache)\n",
        "\n",
        "def process_file(args):\n",
        "    file_path, genre = args\n",
        "    data = []\n",
        "    try:\n",
        "        y, sr = librosa.load(file_path)\n",
        "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
        "        tags = [\"original\", \"stretch\", \"pitch\", \"noise\"]\n",
        "        versions = [\n",
        "            y,\n",
        "            librosa.effects.time_stretch(y, rate=0.9),\n",
        "            librosa.effects.pitch_shift(y, sr=sr, n_steps=2),\n",
        "            y + 0.005 * np.random.randn(len(y))\n",
        "        ]\n",
        "\n",
        "        for tag, version in zip(tags, versions):\n",
        "            cache_path = os.path.join(FEATURE_CACHE_DIR, f\"{base_name}_{tag}.pkl\")\n",
        "            if os.path.exists(cache_path):\n",
        "                row = joblib.load(cache_path)\n",
        "            else:\n",
        "                row = extract_features(version, sr, base_name, genre, tag=tag)\n",
        "                if row:\n",
        "                    joblib.dump(row, cache_path)\n",
        "            if row:\n",
        "                data.append(row)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error processing file {file_path}: {e}\")\n",
        "    return data\n",
        "\n",
        "# task list\n",
        "\n",
        "tasks = []\n",
        "start = time.time()\n",
        "for genre in os.listdir(AUDIO_ROOT):\n",
        "    genre_path = os.path.join(AUDIO_ROOT, genre)\n",
        "    if os.path.isdir(genre_path):\n",
        "        for file in os.listdir(genre_path):\n",
        "            if file.endswith(\".au\") or file.endswith(\".wav\"):\n",
        "                tasks.append((os.path.join(genre_path, file), genre))\n",
        "\n",
        "\n",
        "print(f\"ðŸ“‚ Processing {len(tasks)} files...\")\n",
        "start = time.time()\n",
        "data = []\n",
        "with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
        "    results = executor.map(process_file, tasks)\n",
        "    for res in results:\n",
        "        data.extend(res)\n",
        "end = time.time()\n",
        "print(f\"âœ… à¸”à¸¶à¸‡ feature à¹€à¸ªà¸£à¹‡à¸ˆà¹ƒà¸™ {end - start:.2f} à¸§à¸´à¸™à¸²à¸—à¸µ\")\n",
        "\n",
        "# âœ… à¸ªà¸£à¹‰à¸²à¸‡ DataFrame\n",
        "print(\"âœ… Extracting to CSV...\")\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(OUTPUT_CSV, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeszNuj8rJgC",
        "outputId": "0b49025c-679f-4fa6-920d-45802aa014a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“‚ Processing 1000 files...\n",
            "âœ… à¸”à¸¶à¸‡ feature à¹€à¸ªà¸£à¹‡à¸ˆà¹ƒà¸™ 2083.26 à¸§à¸´à¸™à¸²à¸—à¸µ\n",
            "âœ… Extracting to CSV...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ðŸ“¥ Load data\n",
        "df = pd.read_csv(\"/content/audio_features_augmented.csv\")\n",
        "\n",
        "# ðŸ”§ Convert columns to numeric (handle list-in-string like \"[107.6]\")\n",
        "df[\"bpm\"] = df[\"bpm\"].apply(lambda x: eval(x)[0] if isinstance(x, str) and \"[\" in x else x)\n",
        "\n",
        "# ðŸ” Convert all relevant columns to float safely\n",
        "columns_to_convert = [\"bpm\", \"pitch\"] + [f\"mfcc_{i}\" for i in range(13)]\n",
        "for col in columns_to_convert:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# ðŸ§¹ Drop rows with missing values in selected columns\n",
        "df = df.dropna(subset=columns_to_convert)\n",
        "\n",
        "# ðŸ§  Define playlist classification rule-based labels\n",
        "def classify_playlist(row):\n",
        "    labels = []\n",
        "    if row[\"bpm\"] > 130 and row[\"mfcc_0\"] > -150:\n",
        "        labels.append(\"workout\")\n",
        "    if row[\"pitch\"] < 120 and row[\"mfcc_1\"] < 0:\n",
        "        labels.append(\"study\")\n",
        "    if row[\"bpm\"] < 100 and row[\"mfcc_2\"] < 5:\n",
        "        labels.append(\"chill\")\n",
        "    if row[\"mfcc_0\"] > -90 and row[\"bpm\"] > 100:\n",
        "        labels.append(\"party\")\n",
        "    if row[\"bpm\"] > 80 and row[\"mfcc_0\"] < -100:\n",
        "        labels.append(\"focus\")\n",
        "    if row[\"mfcc_1\"] > 5 and row[\"pitch\"] > 130:\n",
        "        labels.append(\"dance\")\n",
        "    if row[\"bpm\"] > 120 and row[\"mfcc_3\"] > 0:\n",
        "        labels.append(\"energetic\")\n",
        "    if row[\"pitch\"] > 150 and row[\"mfcc_5\"] < 3:\n",
        "        labels.append(\"mood_boost\")\n",
        "    if row[\"bpm\"] < 90 and row[\"mfcc_4\"] < -2:\n",
        "        labels.append(\"relax\")\n",
        "    if row[\"mfcc_2\"] > 10 and row[\"pitch\"] < 100:\n",
        "        labels.append(\"ambient\")\n",
        "    if row[\"bpm\"] < 60 and row[\"mfcc_0\"] < -200:\n",
        "        labels.append(\"sleep\")\n",
        "\n",
        "    # If no labels are assigned, return 'relax' as a default\n",
        "    if not labels:\n",
        "        return \"relax\"\n",
        "    return labels[0]  # In case multiple labels apply, choose the first one\n",
        "\n",
        "# ðŸ·ï¸ Apply label function\n",
        "df[\"playlist\"] = df.apply(classify_playlist, axis=1)\n",
        "\n",
        "\n",
        "# ðŸŽ¯ Features and target\n",
        "X = df[columns_to_convert]\n",
        "y = df[\"playlist\"]\n",
        "\n",
        "# âš–ï¸ Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# âœ‚ï¸ Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ðŸŒ² Train model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ðŸ” Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# ðŸ“Š Report\n",
        "print(\"ðŸŽ¯ Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# ðŸ”® Predict for the entire dataset\n",
        "y_prob = model.predict_proba(X_scaled)\n",
        "\n",
        "# ðŸŽ¯ Select the highest probability label for each song\n",
        "df[\"playlist_predicted\"] = [model.classes_[prob.argmax()] for prob in y_prob]\n",
        "\n",
        "# ðŸ“ Calculate probabilities\n",
        "df[\"playlist_probabilities\"] = [max(prob) for prob in y_prob]\n",
        "\n",
        "# ðŸ’¾ Save to new CSV\n",
        "df.to_csv(\"/content/audio_features_with_single_playlist_prediction.csv\", index=False)\n",
        "print(\"âœ… Saved: /content/audio_features_with_single_playlist_prediction.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpsGGzhnB9lX",
        "outputId": "16a1b1d1-3ba0-41e5-f68e-2f64a86e5fba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     ambient       1.00      1.00      1.00         2\n",
            "       chill       1.00      1.00      1.00       135\n",
            "       dance       0.94      0.94      0.94        16\n",
            "   energetic       1.00      0.62      0.77         8\n",
            "       focus       0.98      1.00      0.99       381\n",
            "       party       0.98      1.00      0.99       125\n",
            "       relax       0.97      0.91      0.94        33\n",
            "     workout       0.98      0.95      0.96       100\n",
            "\n",
            "    accuracy                           0.98       800\n",
            "   macro avg       0.98      0.93      0.95       800\n",
            "weighted avg       0.98      0.98      0.98       800\n",
            "\n",
            "âœ… Saved: /content/audio_features_with_single_playlist_prediction.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# Save model\n",
        "joblib.dump(model, \"playlist_classifier_model.joblib\")\n",
        "# Save scaler\n",
        "joblib.dump(scaler, \"scaler.joblib\")\n",
        "print(\"âœ… Model and scaler saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHp587M1kBEX",
        "outputId": "d830b2dd-a1ba-4869-cba3-e645a307a36c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model and scaler saved.\n"
          ]
        }
      ]
    }
  ]
}